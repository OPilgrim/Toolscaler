{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and decompress [data.tar.gz](https://huggingface.co/datasets/reasonwang/ToolGen-Datasets/blob/main/data.tar.gz). Other datasets are at [ToolGen-Datasets](https://huggingface.co/datasets/reasonwang/ToolGen-Datasets).\n",
    "\n",
    "'''\n",
    "pip install:\n",
    "    deepspeed\n",
    "    UniTok\n",
    "    pigmento\n",
    "    refconfig\n",
    "    fastparquet\n",
    "    transformers==4.40.0\n",
    "    tokenizers==0.19.1\n",
    "    numpy==1.25.2\n",
    "    pyarrow==18.1.0\n",
    "    backoff==2.2.1\n",
    "    click==8.1.7\n",
    "    faiss_cpu\n",
    "    Flask==3.0.3\n",
    "    flask_cors==5.0.0\n",
    "    fschat==0.2.36\n",
    "    httpx==0.27.2\n",
    "    huggingface_hub==0.24.6\n",
    "    nltk==3.9.1\n",
    "    openai\n",
    "    pandas==2.2.3\n",
    "    peft\n",
    "    psutil\n",
    "    pydantic==2.9.2\n",
    "    rank_bm25==0.2.2\n",
    "    Requests==2.32.3\n",
    "    scikit_learn==1.5.2\n",
    "    scipy==1.14.1\n",
    "    sentence_transformers==3.1.0\n",
    "    tenacity==8.5.0\n",
    "    termcolor==2.5.0\n",
    "    tiktoken==0.7.0\n",
    "    torch==2.4.1\n",
    "    tqdm\n",
    "    Unidecode\n",
    "    fastapi==0.110.0\n",
    "    PyYAML==6.0.1\n",
    "    slowapi==0.1.9\n",
    "    uvicorn==0.28.0\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the training data required by the codebook from the tools.json file of ToolBench, and transfer it to GenCodebook\\data\\tb_train and GenCodebook\\data\\tb_dev directories.\n",
    "import json\n",
    "import csv\n",
    "\"\"\"\n",
    "{\n",
    "    'product_id': 'api_2c3bbf59-df39-4b01-b91b-0f176c8effd9', \n",
    "    'tool_description': \"Extract the information on a Thai driver's license and return text results such as driver's license number and personal information.\", \n",
    "    'home_url': 'https://rapidapi.com/the-brainstem-brainbotapi/api/thai-drivers-license-ocr/', \n",
    "    'name': 'Thai Drivers License OCR', \n",
    "    'title': 'Thai Drivers License OCR', \n",
    "    'pricing': 'FREEMIUM', \n",
    "    'tool_name': 'Thai Drivers License OCR', \n",
    "    'score': None, \n",
    "    'host': 'thai-drivers-license-ocr.p.rapidapi.com', \n",
    "    'api_list': [{\n",
    "        'name': \"Driver's  License\", \n",
    "        'url': 'https://thai-drivers-license-ocr.p.rapidapi.com/api/v1/ocr-licensedriver', \n",
    "        'description': \"Extract the information on a Thai driver's license and return text results such as driver's license number and personal information.\", \n",
    "        'method': 'POST', \n",
    "        'required_parameters': [], \n",
    "        'optional_parameters': [], \n",
    "        'code': 'import requests\\n\\nurl = \"https://thai-drivers-license-ocr.p.rapidapi.com/api/v1/ocr-licensedriver\"\\n\\nheaders = {\\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\\n            \"X-RapidAPI-Host\": \"thai-drivers-license-ocr.p.rapidapi.com\"\\n        }\\n\\nresponse = requests.post(url, headers=headers)\\nprint(response.json())\\n', \n",
    "        'convert_code': 'import requests\\n\\nurl = \"https://thai-drivers-license-ocr.p.rapidapi.com/api/v1/ocr-licensedriver\"\\n\\nheaders = {\\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\\n            \"X-RapidAPI-Host\": \"thai-drivers-license-ocr.p.rapidapi.com\"\\n        }\\n\\nresponse = requests.post(url, headers=headers)\\nprint(response.json())\\n', \n",
    "        'test_endpoint': '', \n",
    "        'statuscode': 200, \n",
    "        'schema': {}\n",
    "        }\n",
    "    ], \n",
    "    'category_name': 'Video_Images'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "with open(\"GenCodebook/data/tools.json\", 'r') as f:\n",
    "    tool_infos = json.load(f)\n",
    "\n",
    "all_datas = {\n",
    "    \"aid\": [0],\n",
    "    \"cat\": [\"\"],\n",
    "    \"namedesc\": [\"Finish\"],   # tool_name&&api_name\n",
    "    \"acode\": [\"\"],   # code\n",
    "    \"aexam\": [\"The end of processing.\"]   # desc\n",
    "}\n",
    "idx = 1\n",
    "for tool in tool_infos:\n",
    "    for api in tool[\"api_list\"]:\n",
    "        all_datas[\"aid\"].append(idx)\n",
    "        all_datas[\"cat\"].append(tool['category_name'])\n",
    "        all_datas[\"namedesc\"].append(f\"{tool['tool_name']}&&{api['name']}\")\n",
    "        if \"code\" not in api.keys():\n",
    "            all_datas[\"acode\"].append(\"\")\n",
    "        else:\n",
    "            all_datas[\"acode\"].append(api[\"code\"])\n",
    "        all_datas[\"aexam\"].append(api[\"description\"])\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "def write_to_tsv(data, filename):\n",
    "    columns = list(data.keys())\n",
    "    rows = zip(*(data[col] for col in columns))\n",
    "\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(columns)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "filename = \"GenCodebook/data/tb_train/tools.tsv\"\n",
    "write_to_tsv(all_datas, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the codebook\n",
    "# run train to get the compressing model: \n",
    "# > python worker.py --model llama3 --data tb --batch_size 12 --num_gist 2 --warmup True --mode train\n",
    "# run export to get the gist embedding:\n",
    "# > python worker.py --model llama3 --data tb --batch_size 12 --num_gist 2 --warmup True --mode export\n",
    "# run cluster to get the codebook:\n",
    "# > python cluster_kmeans.py --model llama3 --sign 8fa057 --num_comp 32 --num_clst 512 --num_dept 2\n",
    "# the codebook might named 8fa057@32-512-2.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change codebook number into str, e.g. 1,2 --> <a_1><b_1>\n",
    "import json\n",
    "store_codebook_str = {}\n",
    "codes = {}\n",
    "with open(\"GenCodebook/tuning/Qwen3/8fa057@32-512-2.code\", 'r') as f:\n",
    "    store_codebook = json.load(f)\n",
    "\n",
    "for id, code in store_codebook.items():\n",
    "    codechars = []\n",
    "    for i, c in enumerate(code):\n",
    "        codechars.append(\"<\" + chr(i + ord('a')) + \"_\" + str(c) + \">\")\n",
    "    \n",
    "    code = ' '.join(str(code))\n",
    "    if code not in codes:\n",
    "        codes[code] = 0\n",
    "    codes[code] += 1\n",
    "\n",
    "    store_codebook_str[id] = codechars\n",
    "\n",
    "store_codebook_str[\"aid\"] = [2, 2, 512, max(codes.values())]   # gists, depth, kernels, overlops\n",
    "\n",
    "with open('GenCodebook/tuning/Qwen3/8fa057@32-512-2-2.code', 'w') as f:\n",
    "    json.dump(store_codebook_str, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The process of reusing the codebook\n",
    "# Make sure that the.kmeans file in cluster_kmeans.py is generated properly.\n",
    "# 2. Place the new \"tool.tsv\" file in the \"data/xxx_train\" or \"data/xxx_dev\" folder. Remember to rename the old \"tool.tsv\" file, and also rename the folder \"data/xxx\"\n",
    "# 3. Run the command with \"mode\" set to \"export\" and set \"batch_size\" to 1. This is to enable sign to be distinguishable from the previous one (at this point, the \"./prepare/\" directory will generate a new \"sign\" folder. If the previous \"tool.tsv\" file is not correctly replaced and needs correction, this folder should also be cleaned up afterwards).\n",
    "# 4. Run the python script \"cluster_kmeans_inference.py\", and make sure to correctly replace the paths within it.\n",
    "# 5. The new codebook for the new \"tool.tsv\" file will be generated. You do not need to train the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionary 'Tool2hierarchicalId.json' for tool names and codebooks. This requires reference to ToolGen's Tool2AtomicId.json.\n",
    "import json\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "def remove_accents(text):\n",
    "    return unidecode(text)\n",
    "\n",
    "\n",
    "with open(\"data/Tool2AtomicId.json\", 'r') as f:\n",
    "    Tool2AtomicId = json.load(f)\n",
    "\n",
    "# All \"fil\" values have been changed to \"url\", but there is still an \"e_url_for_audio_transcoder_compression_optimization_download_url\" that needs to be manually modified.\n",
    "AtomicId2Tool = {}\n",
    "for k, v in Tool2AtomicId.items():\n",
    "    # AtomicId2Tool[v] = k\n",
    "    name = k.split(\"_\")\n",
    "    new_name = []\n",
    "    for i in name:\n",
    "        if i == \"fil\":\n",
    "            new_name.append(\"url\")\n",
    "        else:\n",
    "            new_name.append(i)\n",
    "    AtomicId2Tool[v] = \"_\".join(new_name)\n",
    "print(len(AtomicId2Tool))\n",
    "\n",
    "Tool2hierarchicalId = {}\n",
    "\n",
    "tool2id_ = pd.read_csv(\"GenCodebook/data/tb_train/tools.tsv\", sep='\\t').set_index(['namedesc'])['aid'].to_dict()\n",
    "tool2id = {}\n",
    "for key in tool2id_.keys():\n",
    "    tool2id[remove_accents(key)] = tool2id_[key]\n",
    "print(\"tool2id_: \", len(tool2id_))\n",
    "print(\"tool2id: \", len(tool2id))\n",
    "\n",
    "with open(\"GenCodebook/tuning/Qwen3/8fa057@32-512-2-2.code\", 'r') as f:\n",
    "    codebook = json.load(f)\n",
    "\n",
    "for atomicId in AtomicId2Tool.keys():\n",
    "    apiname = atomicId[2:-2]\n",
    "    id = tool2id[apiname]\n",
    "    codebook = \"\".join(list(map(str, codebook[str(id)])))\n",
    "    if atomicId not in AtomicId2Tool:\n",
    "        print(atomicId)\n",
    "        continue\n",
    "    Tool2hierarchicalId[AtomicId2Tool[atomicId]] = codebook\n",
    "print(len(Tool2hierarchicalId))\n",
    "\n",
    "with open(\"data/Tool2hierarchicalId.json\", 'w') as f:\n",
    "    json.dump(Tool2hierarchicalId, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the unique tokens in the codebook, such as <a_1>, <b_1>, to the vocabulary of the base model.\n",
    "import torch\n",
    "import transformers\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Type, cast\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# tool2id\n",
    "tool2id_ = pd.read_csv(\"GenCodebook/data/tb_train/tools.tsv\", sep='\\t').set_index(['namedesc'])['aid'].to_dict()\n",
    "tool2id = {}\n",
    "for key in tool2id_.keys():\n",
    "    tool2id[unidecode(key)] = tool2id_[key]\n",
    "print(\"tool2id_: \", len(tool2id_))\n",
    "print(\"tool2id: \", len(tool2id))\n",
    "\n",
    "# id2embedding\n",
    "id2emb = np.load(\"GenCodebook/tuning/Qwen3/8fa057_reconstructed_32.npy\", allow_pickle=True).item()\n",
    "id2emb = cast(dict, id2emb)\n",
    "\n",
    "# id2union_codebook\n",
    "with open(\"GenCodebook/tuning/Qwen3/8fa057@32-512-2.code\", 'r') as f:\n",
    "    union_codebook = json.load(f)\n",
    "gists, depth, kernels, overlops = union_codebook.pop(\"aid\")\n",
    "runds = gists*depth\n",
    "\n",
    "# kernal's embedding\n",
    "codeId2emb = {}\n",
    "for item, code in union_codebook.items():\n",
    "    for i, codeId in enumerate(code):\n",
    "        if i == len(code)-1:\n",
    "            break\n",
    "        if codeId not in codeId2emb:\n",
    "            codeId2emb[codeId] = []\n",
    "        codeId2emb[codeId].append(id2emb[item][i])\n",
    "print(codeId2emb.keys())\n",
    "\n",
    "new_tokens = []\n",
    "for pos in range(runds):\n",
    "    new_tokens.extend([f\"<{chr(pos + ord('a'))}_{i}>\" for i in range(kernels)])\n",
    "\n",
    "# Load tokenizer and add tokens into vocabulary\n",
    "model_name_or_path = \"models/qwen2.5-3B\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "num_added_tokens = tokenizer.add_tokens(new_tokens=new_tokens, special_tokens=False)\n",
    "print(f\"Added {num_added_tokens} new tokens. Model now has {len(tokenizer)} tokens.\")\n",
    "\n",
    "# Load model and expand embeddings\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "for codeId, embs in codeId2emb.items():\n",
    "    token_id = tokenizer(codeId, add_special_tokens=False).input_ids\n",
    "    assert len(token_id) == 1\n",
    "\n",
    "    if chr(runds + ord('a')) not in codeId:\n",
    "        embedding = torch.mean(torch.from_numpy(np.array(embs)), dim=0)\n",
    "        # print(codeId, embedding.shape)\n",
    "        embedding_dim = model.model.embed_tokens.weight.data.size(1)\n",
    "        assert embedding.shape[0] == embedding_dim, f\"Embedding dimension mismatch: {embedding.shape[0]} != {embedding_dim}\"\n",
    "        model.model.embed_tokens.weight.data[token_id[0]] = embedding\n",
    "    else:\n",
    "        print(\"?\")\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(\"models/qwen2.5-3B-virtualized-2@2\", safe_serialization=True)\n",
    "tokenizer.save_pretrained(\"models/qwen2.5-3B-virtualized-2@2\")\n",
    "# tool2id_:  46985\n",
    "# tool2id:  46985\n",
    "# Added 2048 new tokens. Model now has 130304 tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct domain-specific training data, including query-tool pairs and trajectories\n",
    "import re\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "tool2id_ = pd.read_csv(\"GenCodebook/data/tb_train/tools.tsv\", sep='\\t').set_index(['namedesc'])['aid'].to_dict()\n",
    "tool2id = {}\n",
    "for key in tool2id_.keys():\n",
    "    decoded_key = key.encode('utf-8').decode('unicode_escape')\n",
    "    tool2id[unidecode(decoded_key)] = tool2id_[key]\n",
    "    tool2id[unidecode(key)] = tool2id_[key]\n",
    "print(\"tool2id_: \", len(tool2id_))\n",
    "print(\"tool2id: \", len(tool2id))\n",
    "\n",
    "import json\n",
    "with open(\"data/toolgen_atomic_retrieval_G123.json\", 'r') as f:\n",
    "    toolgen_atomic_retrieval_G123 = json.load(f)\n",
    "print(\"toolgen_atomic_retrieval_G123: \", len(toolgen_atomic_retrieval_G123))\n",
    "with open(\"data/toolgen_atomic_G123_dfs.json\", 'r') as f:\n",
    "    toolgen_atomic_G123_dfs = json.load(f)\n",
    "print(\"toolgen_atomic_G123_dfs: \", len(toolgen_atomic_G123_dfs))\n",
    "\n",
    "\n",
    "with open(\"GenCodebook/tuning/Qwen3/8fa057@32-512-2-2.code\", 'r') as f:\n",
    "    store_codebook = json.load(f)\n",
    "print(\"store_codebook: \", len(store_codebook))\n",
    "\n",
    "# ===\n",
    "toolscaler_hierarchical_retrieval_G123 = []\n",
    "for item in toolgen_atomic_retrieval_G123:\n",
    "    if \"conversations\" in item:\n",
    "        tool_api = item[\"conversations\"][1][\"content\"][2:-2]\n",
    "        id = tool2id[tool_api]\n",
    "        codebook = \"\".join(store_codebook[str(id)])\n",
    "        # print(tool_api, id, codebook)\n",
    "        item[\"conversations\"][1][\"content\"] = codebook\n",
    "        toolscaler_hierarchical_retrieval_G123.append(item)\n",
    "    # print(item)\n",
    "    else:\n",
    "        print(item)\n",
    "\n",
    "with open(\"data/toolscaler_hierarchical_2@2_retrieval_G123_qwen3.json\", 'w') as f:\n",
    "    json.dump(toolscaler_hierarchical_retrieval_G123, f, indent=4)\n",
    "\n",
    "\n",
    "# ===\n",
    "def replace_custom_tags(text):\n",
    "    \"\"\"\n",
    "    替换文本中所有<<...>>结构为映射字典中对应的值\n",
    "    \n",
    "    :param text: 原始文本字符串\n",
    "    :return: 替换后的文本字符串\n",
    "    \"\"\"\n",
    "    pattern = r'<<(.*?)>>'  # 非贪婪匹配<<...>>中的内容\n",
    "    def replacer(match):\n",
    "        name = match.group(1)   # Tool_name&&Api_name\n",
    "        decoded_name = name.encode('utf-8').decode('unicode_escape')\n",
    "        if unidecode(decoded_name) in tool2id:\n",
    "            id = tool2id[unidecode(decoded_name)]\n",
    "            codebook = \"\".join(store_codebook[str(id)])\n",
    "        else:\n",
    "            codebook = f\"<<{name}>>\"\n",
    "            # print(codebook)\n",
    "        return codebook\n",
    "    return re.sub(pattern, replacer, text)\n",
    "\n",
    "toolscaler_hierarchical_G123_dfs = []\n",
    "for item in toolgen_atomic_G123_dfs:\n",
    "    if \"conversations\" in item:\n",
    "        for i, step in enumerate(item[\"conversations\"]):\n",
    "            sentence = step[\"value\"]\n",
    "            item[\"conversations\"][i][\"value\"] = replace_custom_tags(sentence)\n",
    "    else:\n",
    "        print(\"something wrong: \", item)\n",
    "    toolscaler_hierarchical_G123_dfs.append(item)\n",
    "\n",
    "with open(\"data/toolscaler_hierarchical_2@2_G123_dfs_qwen3.json\", 'w') as f:\n",
    "    json.dump(toolscaler_hierarchical_G123_dfs, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install llama-factory, and then configure the information of the dataset in LLaMA-Factory/data/dataset_info.json, such as:\n",
    "\"\"\"\n",
    "\"toolscaler_hierarchical_2@2_retrieval_G123_qwen3\": {\n",
    "    \"file_name\": \"data/toolscaler_hierarchical_2@2_retrieval_G123_qwen3.json\",\n",
    "    \"formatting\": \"sharegpt\",\n",
    "    \"columns\": {\n",
    "      \"messages\": \"conversations\"\n",
    "    },\n",
    "    \"tags\": {\n",
    "      \"role_tag\": \"role\",\n",
    "      \"content_tag\": \"content\",\n",
    "      \"user_tag\": \"user\",\n",
    "      \"assistant_tag\": \"assistant\"\n",
    "    }\n",
    "  },\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toolscaler Retrieval - Full-scale fine-tuning:\n",
    "# > CUDA_VISIBLE_DEVICES=1,2,3,4 FORCE_TORCHRUN=1 llamafactory-cli train Scripts/full/gist_ret_sft_ds3.yaml\n",
    "# \n",
    "#   Eval the retrieval model with NDCG:\n",
    "#   > cp data/Tool2hierarchicalId.json Evaluator/data/toolenv/Tool2hierarchicalId.json\n",
    "#   > cd Evaluator\n",
    "#   > python eval_toolscaler_qwen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToolScaler E2E - Full-scale fine-tuning:\n",
    "# > bash E2eTraining\\scripts\\train.sh\n",
    "# \n",
    "#   Eval the E2E model with StableToolBench:\n",
    "#   Get ToolBench key from https://github.com/OpenBMB/ToolBench repo. Then deploy https://github.com/THUNLP-MT/StableToolBench following the instructions in their repo.\n",
    "#   To start StableToolBench/server, run the following command in the folder: \n",
    "#   > tmux new -d -s e2e 'python main.py > out.log 2>&1'\n",
    "#   > cd Evaluator\n",
    "#   > bash scripts/inference/inference_toolscaler_pipeline_virtual.sh\n",
    "#   > bash scripts/convert_answer/run_convert_answer.sh\n",
    "#   > bash scripts/pass_rate/run_pass_rate.sh\n",
    "#   > bash scripts/preference/run_preference.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
